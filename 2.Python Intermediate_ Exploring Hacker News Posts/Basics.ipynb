{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Hacker News Project\n",
    "\n",
    "This is my second project on the way to become a data analyst. In this project we will analyst a data set of submissions to popular technology site Hacker News. I'm going to do this project under the guide from dataquest.io, they will told me what to do a i will present it here.\n",
    "Hacker News is a site started by the startup incubator Y Combinator, where user-submitted stories (known as \"posts\") are voted and commented upon, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of Hacker News' listings can get hundreds of thousands of visitors as a result.\n",
    "You can find the data set [here](https://www.kaggle.com/hacker-news/hacker-news-posts)\n",
    "\n",
    "We'll compare these two types of posts to determine the following:\n",
    "* Do Ask HN or Show HN receive more comments on average?\n",
    "* Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "Let's start by importing the libraries we need and reading the data set into a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "opened_file = open('hacker_news.csv', encoding='utf8')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "headers = hn[:1]\n",
    "hn = hn[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below code, i will define a function to print data sample for any dataset, also inform number of rows and column of entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']]\n",
      "\n",
      "\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "\n",
      "\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "\n",
      "\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']\n",
      "\n",
      "\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']\n",
      "\n",
      "\n",
      "['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']\n",
      "\n",
      "\n",
      "Number of rows:  20100\n",
      "Number of columns:  7\n"
     ]
    }
   ],
   "source": [
    "def explore_data(dataset, start, end, rows_and_col=False):\n",
    "    for row in dataset[start:end]:\n",
    "        print(row)\n",
    "        print('\\n') #new empty line\n",
    "    if rows_and_col:\n",
    "        print('Number of rows: ',len(dataset))\n",
    "        print('Number of columns: ',len(dataset[0]))\n",
    "        \n",
    "#print first 5 row of dataset\n",
    "print(headers)\n",
    "print('\\n')\n",
    "explore_data(hn, 0, 5, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only concern with post titles beginning with `Aks HN` and `Show HN`, we'll use a string method `startswith`, it will return `True` or `False` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ask_posts= []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "#print(len(ask_posts))\n",
    "#print(len(show_posts))\n",
    "#print(len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view some first row of `ask_posts` and `show_posts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55']\n",
      "\n",
      "\n",
      "['10610020', 'Ask HN: Am I the only one outraged by Twitter shutting down share counts?', '', '28', '29', 'tkfx', '11/22/2015 13:43']\n",
      "\n",
      "\n",
      "['11610310', 'Ask HN: Aby recent changes to CSS that broke mobile?', '', '1', '1', 'polskibus', '5/2/2016 10:14']\n",
      "\n",
      "\n",
      "['12210105', 'Ask HN: Looking for Employee #3 How do I do it?', '', '1', '3', 'sph130', '8/2/2016 14:20']\n",
      "\n",
      "\n",
      "['10394168', 'Ask HN: Someone offered to buy my browser extension from me. What now?', '', '28', '17', 'roykolak', '10/15/2015 16:38']\n",
      "\n",
      "\n",
      "Number of rows:  1744\n",
      "Number of columns:  7\n"
     ]
    }
   ],
   "source": [
    "explore_data(ask_posts, 0, 5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10627194', 'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform', 'https://iot.seeed.cc', '26', '22', 'kfihihc', '11/25/2015 14:03']\n",
      "\n",
      "\n",
      "['10646440', 'Show HN: Something pointless I made', 'http://dn.ht/picklecat/', '747', '102', 'dhotson', '11/29/2015 22:46']\n",
      "\n",
      "\n",
      "['11590768', 'Show HN: Shanhu.io, a programming playground powered by e8vm', 'https://shanhu.io', '1', '1', 'h8liu', '4/28/2016 18:05']\n",
      "\n",
      "\n",
      "['12178806', 'Show HN: Webscope  Easy way for web developers to communicate with Clients', 'http://webscopeapp.com', '3', '3', 'fastbrick', '7/28/2016 7:11']\n",
      "\n",
      "\n",
      "['10872799', 'Show HN: GeoScreenshot  Easily test Geo-IP based web pages', 'https://www.geoscreenshot.com/', '1', '9', 'kpsychwave', '1/9/2016 20:45']\n",
      "\n",
      "\n",
      "Number of rows:  1162\n",
      "Number of columns:  7\n"
     ]
    }
   ],
   "source": [
    "explore_data(show_posts, 0, 5, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let calculate which dataset have more comments on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average numbers of comment on ask posts:  14.038417431192661\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    cm_num = int(row[4])\n",
    "    total_ask_comments += cm_num\n",
    "    \n",
    "avg_ask_comment = total_ask_comments / len(ask_posts)\n",
    "\n",
    "print('Average numbers of comment on ask posts: ',avg_ask_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average numbers of comment on ask posts:  10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_show_comments = 0\n",
    "\n",
    "for row in show_posts:\n",
    "    cm_num = int(row[4])\n",
    "    total_show_comments += cm_num\n",
    "    \n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "\n",
    "print('Average numbers of comment on ask posts: ',avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, on average, Ask post receive more comment than show post. This might point out that Hacker news community is helpful to people in need.\n",
    "\n",
    "Above, we have found out that, on average, ask posts receive more comments than show posts. Therefor, we'll focus our remaining analysis just on ask posts.\n",
    "\n",
    "Next, we will determine  if ask posts created at a certain time are more likely to attract comments. We'll use the following steps to perform this analysis:\n",
    "1. Calculate the amount of ask posts created in each hour of the day, along with the number of comments received\n",
    "2. Calculate the average number of comments ask posts receive by hour created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "for row in ask_posts:\n",
    "    created_at = dt.datetime.strptime(row[6],'%m/%d/%Y %H:%M')\n",
    "    cm_num = int(row[4])\n",
    "    result_list.append([created_at,cm_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_by_hour ={}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in result_list:\n",
    "    hour = dt.datetime.strftime(row[0],'%H')\n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = row[1]\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_by_hours = []\n",
    "\n",
    "for hour in counts_by_hour:\n",
    "    avg_by_hours.append([hour,comments_by_hour[hour]/counts_by_hour[hour]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', 13.440677966101696]\n",
      "['05', 10.08695652173913]\n",
      "['04', 7.170212765957447]\n",
      "['23', 7.985294117647059]\n",
      "['01', 11.383333333333333]\n",
      "['12', 9.41095890410959]\n",
      "['02', 23.810344827586206]\n",
      "['17', 11.46]\n",
      "['08', 10.25]\n",
      "['15', 38.5948275862069]\n",
      "['09', 5.5777777777777775]\n",
      "['14', 13.233644859813085]\n",
      "['03', 7.796296296296297]\n",
      "['06', 9.022727272727273]\n",
      "['20', 21.525]\n",
      "['00', 8.127272727272727]\n",
      "['07', 7.852941176470588]\n",
      "['11', 11.051724137931034]\n",
      "['22', 6.746478873239437]\n",
      "['21', 16.009174311926607]\n",
      "['16', 16.796296296296298]\n",
      "['19', 10.8]\n",
      "['18', 13.20183486238532]\n",
      "['13', 14.741176470588234]\n"
     ]
    }
   ],
   "source": [
    "for row in avg_by_hours:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we now have the results we need, this format makes it hard to identify the hours with the highest values. Let's finish by sorting the list of lists and printing the five highest values in a format that's easier to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.440677966101696, '10']\n",
      "[10.08695652173913, '05']\n",
      "[7.170212765957447, '04']\n",
      "[7.985294117647059, '23']\n",
      "[11.383333333333333, '01']\n",
      "[9.41095890410959, '12']\n",
      "[23.810344827586206, '02']\n",
      "[11.46, '17']\n",
      "[10.25, '08']\n",
      "[38.5948275862069, '15']\n",
      "[5.5777777777777775, '09']\n",
      "[13.233644859813085, '14']\n",
      "[7.796296296296297, '03']\n",
      "[9.022727272727273, '06']\n",
      "[21.525, '20']\n",
      "[8.127272727272727, '00']\n",
      "[7.852941176470588, '07']\n",
      "[11.051724137931034, '11']\n",
      "[6.746478873239437, '22']\n",
      "[16.009174311926607, '21']\n",
      "[16.796296296296298, '16']\n",
      "[10.8, '19']\n",
      "[13.20183486238532, '18']\n",
      "[14.741176470588234, '13']\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "for row in avg_by_hours:\n",
    "    swap_avg_by_hour.append([row[1],row[0]])\n",
    "    \n",
    "for row in swap_avg_by_hour:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_swap =  sorted(swap_avg_by_hour, reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38.5948275862069, '15']\n",
      "[23.810344827586206, '02']\n",
      "[21.525, '20']\n",
      "[16.796296296296298, '16']\n",
      "[16.009174311926607, '21']\n",
      "[14.741176470588234, '13']\n",
      "[13.440677966101696, '10']\n",
      "[13.233644859813085, '14']\n",
      "[13.20183486238532, '18']\n",
      "[11.46, '17']\n",
      "[11.383333333333333, '01']\n",
      "[11.051724137931034, '11']\n",
      "[10.8, '19']\n",
      "[10.25, '08']\n",
      "[10.08695652173913, '05']\n",
      "[9.41095890410959, '12']\n",
      "[9.022727272727273, '06']\n",
      "[8.127272727272727, '00']\n",
      "[7.985294117647059, '23']\n",
      "[7.852941176470588, '07']\n",
      "[7.796296296296297, '03']\n",
      "[7.170212765957447, '04']\n",
      "[6.746478873239437, '22']\n",
      "[5.5777777777777775, '09']\n"
     ]
    }
   ],
   "source": [
    "for row in sorted_swap:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "print('Top 5 Hours for Ask Posts Comments')\n",
    "template_string = \"{}: {:.2f} average comments per post\"\n",
    "for row in sorted_swap[:5]:\n",
    "    hour = dt.datetime.strptime(row[1],'%H')\n",
    "    hour_string = dt.datetime.strftime(hour,'%H:%M')\n",
    "    print(template_string.format(hour_string,row[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
